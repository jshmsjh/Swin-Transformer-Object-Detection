# 目标检测与实例分割

基于 Swin Transformer 的目标检测与实例分割实战

此报告的内容包括：

1. 如何利用预训练网络实现基于Swin Transformer的目标检测与实例分割；

2. 如何标注目标检测与分割数据集，以及数据集类型转化

3. 如何利用自制数据集在预训练网络上微调，实现对特定类别的目标检测与实例分割；

4. 如何自定义目标检测与实例分割的可视化输出结果；

5. 基于Swin Transformerd的目标检测网络与其他经典网络的对比；

## Mmdetection 安装

环境配置与安装详见：[https://mmdetection.readthedocs.io/en/latest/get_started.html#installation](https://mmdetection.readthedocs.io/en/latest/get_started.html)

<img src=".\pic\图片1.png" alt="图片1" style="zoom:67%;" />

我们运行的：

```
pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu110/torch1.7.0/index.html\
git clone https://github.com/SwinTransformer/Swin-Transformer-Object-Detection.git
cd Swin-Transformer-Object-Detection
pip install -r requirements/build.txt
pip install -v -e . # or "python setup.py develop"
```

检测是否安装成功的代码为`./ourtest.py`

## 利用swin_transformer在github提供的在coco数据集预训练的网络进行目标检测

预训练模型在https://github.com/SwinTransformer/Swin-Transformer-Object-Detection下载并放入`./checkpoints`文件夹下：

在`./config`内找到与所下载的预训练模型结构和数据集相对应的配置文件

<img src=".\pic\图片2.png" alt="图片2" style="zoom:67%;" />

例如：

预训练模型 `cascade_mask_rcnn_swin_base_patch4_window7.pth`的对应配置文件为

```
./configs/swin/cascade_mask_rcnn_swin_base_patch4_window7_mstrain_480-800_giou_4conv1f_adamw_3x_coco.py
```

如果目标检测时出现warning：

请将所用`./configs/_base_/datasets`地址下的配置文件进行如下图所示的更改：

<img src=".\pic\图片3.png" alt="图片3" style="zoom:67%;" />

在`./ourtest.py`，更改网络配置文件与预训练模型文件地址后，即可实现对coco数据集内类别物体的目标检测。

视频的检测脚本:

```
python demo/video_demo.py \
  ${VIDEO_FILE} \
  ${CONFIG_FILE} 
  ${CHECKPOINT_FILE} \
  [--device ${GPU_ID}] \
  [--score-thr ${SCORE_THR}] \
  [--out ${OUT_FILE}] \
  [--show] \
  --wait-time ${WAIT_TIME}]
```

样例：

```
python demo/video_demo.py viedo.mp4 \
  configs/swin/cascade_mask_rcnn_swin_base_patch4_window7_mstrain_480-800_giou_4conv1f_adamw_3x_coco.py\
  checkpoints/cascade_mask_rcnn_swin_base_patch4_window7.pth\
  --out result.mp4
```

检测结果展示：

<img src=".\pic\图片4.png" alt="图片4" style="zoom:67%;" />

配置文件结构与命名规则：

https://mmdetection.readthedocs.io/en/latest/tutorials/config.html

## 标注自己的数据集

### 目标检测数据集标注与制作VOC2007格式数据集

目标检测标注工具：labelImg

Windows免安装版本：./labelImg.zip

解压后:

<img src=".\pic\图片5.png" alt="图片5" style="zoom:67%;" />

data文件夹内的predefined_classes.txt为待标注的类别名称，根据需求更改:

<img src=".\pic\图片6.png" alt="图片6" style="zoom:67%;" />

点击exe文件运行labelImg:

<img src=".\pic\图片7.png" alt="图片7" style="zoom:80%;" />

标注教程:

![图片8](.\pic\图片8.png)

我们的labelImg界面，将标注文件保存成Pascal VOC格式（xml文件）:

<img src=".\pic\图片9.png" alt="图片9" style="zoom: 50%;" /><img src="D:\object_detec\pic\图片10.png" alt="图片10" style="zoom: 67%;" />



将xml标注文件与jpg图片文件整理成Pascal VOC格式:

├── VOCdevkit

│  ├── VOC2007

│  │  ├── Annotations

│  │  ├── ImageSets ── Main

│  │  ├── JPEGImages

<img src=".\pic\图片11.png" alt="图片11" style="zoom:67%;" /><img src=".\pic\图片12.png" alt="图片12" style="zoom:67%;" />



将我们提供的代码`./code/voc_trainval_divide.py`放在VOC2007目录下，运行 `python ./code/voc_trainval_divide.py`，即可在ImageSets/Main中得到训练集、验证集、测试集结果划分:

<img src=".\pic\图片13.png" alt="图片13" style="zoom:67%;" />

最后将数据集以如图格式放置在mmdetection的文件目录中:

<img src=".\pic\图片14.png" alt="图片14" style="zoom:67%;" />

### VOC2007格式数据集转coco格式数据集

由于mmdetection对coco类型的数据集的支持更好，我们介绍如何将VOC2007格式数据集转换为coco格式数据集，我们也推荐在mmdetection中使用coco格式数据集。

mmdetection提供了相关代码，路径`./tools/dataset_converters`下有如下两个格式转化文件：

<img src=".\pic\图片15.png" alt="图片15" style="zoom:67%;" />

将之前的VOC2007格式数据集按要求放置之后，运行如下脚本即可在`./data/coco/annotations`内得到coco格式的json文件:

```
python tools/dataset_converters/pascal_voc.py \
  ./data/VOCdevkit \
  --out-dir ./data/coco/annotations \
```

更改训练与验证集json文件名称如下:

<img src=".\pic\图片16.png" alt="图片16" style="zoom:67%;" />

之后在coco文件夹内，建立train2017和val2017文件夹，分别保存训练集与验证集图片文件:

<img src=".\pic\图片17.png" alt="图片17" style="zoom:67%;" />

<img src=".\pic\图片18.png" alt="图片18" style="zoom:67%;" />

在json文件中查看训练集与验证集包含的图片文件名:

<img src="\pic\图片19.png" alt="图片19" style="zoom:61%;" />

### 实例分割数据集标注与coco格式数据集制作：

标注工具：labelme

详细教程：https://blog.csdn.net/qq_38451119/article/details/83036495?spm=1001.2101.3001.6650.3&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-3.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-3.nonecase

1.安装Anaconda

2.输入下面的指令进行labelme的安装：

```
conda create --name=labelme python=3.6
conda activate labelme
pip install pyqt5
pip install labelme
```

3.在命令行中输入labelme，即可进去GUI界面：

<img src=".\pic\图片20.png" alt="图片20" style="zoom:61%;" />

标注工具labelme的使用方法与之前的labelImg类似，区别在于不局限于矩形标注框，可以用任意边数闭合的多边形将物体描边标注，以实现精准分割：

<img src=".\pic\图片21.png" alt="图片21" style="zoom: 50%;" /><img src=".\pic\图片22.png" alt="图片22" style="zoom: 67%;" />



保存的标注文件为.json文件：

<img src=".\pic\图片23.png" alt="图片23" style="zoom:67%;" />



原始labelme数据目录结构如下：

```
|-- images 
|     |---  1.jpg 
|     |---  1.json 
|     |---  2.jpg 
|     |---  2.json 
|     |---  ....... 
|-- labelme2coco.py 
|-- labels.txt
```

- imges目录下就是你的数据集原始图片，加上labelme标注的json文件。
- labelme2coco.py源码放到最后。
- labels.txt就是你的类别标签，假设我有两个类（lm，ls），那么对应的labels.txt内容如下：

```
__ignore__
_background_
lm
ls
```

在`./code/labelme2coco.py`文件的目录下，打开命令行执行：

```
python labelme2coco.py --input_dir images --output_dir coco --labels labels.txt
```

- --input_dir：指定images文件夹
- --output_dir：指定你的输出文件夹
- --labels：指定你的labels.txt文件

生成的coco数据集目录结构如下：

```
|-- annotations
| 	|---  instances_train2017.json
|       |---  instances_val2017.json
|-- train2017
| 	|---  2.jpg
| 	|---  5.jpg
| 	|---  .......
|-- val2017
| 	|---  1.jpg
| 	|---  3.jpg
| 	|---  .......
|-- visualization
| 	|---  1.jpg
| 	|---  2.jpg
| 	|---  ......
```

按如下格式放置:

<img src=".\pic\图片24.png" alt="图片24" style="zoom:67%;" />

## 在预训练网络上用自制数据集微调

### 以faster_rcnn+voc为例讲解目标识别

Voc的目标分割数据集与coco格式实例分割数据集制作方法在第二部分已经详细介绍过，下面主要介绍配置文件的修改。

预训练网络结构：faster_rcnn_r50_fpn 

在coco数据集上预训练 ，下载地址如下：

*http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth* 

1. 更改CLASSES为自己数据集内的类别 `./mmdet/datasets/voc.py`

![图片25](.\pic\图片25.png)

2. 更改voc_classes为自己数据集内的类别`./mmdet/core/evaluation/class_names.py`

![图片26](.\pic\图片26.png)

3. 更改num_classes为自己数据集内的类别数量`./configs/_base_/models/faster_rcnn_r50_fpn.py`

![图片27](.\pic\图片27.png)

将自动下载预训练模型，并继承除预测头之外的模型权重数据:

![图片28](.\pic\图片28.png)

4. 至此运行如下脚本即可开始训练，但还有可更改的配置，下面介绍

```
python ./tools/train.py configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py
```

5. 训练时各项配置`./configs/_base_/default_runtime.py`

<img src=".\pic\图片29.png" alt="图片29" style="zoom:61%;" />

6. 训练计划配置`./configs/_base_/schedules/schedule_1x.py`

<img src=".\pic\图片30.png" alt="图片30" style="zoom:61%;" />

7. 图片在训练或检测之前会转化成img_scales设定的大小，当img_scale小于原图片尺寸时，img_scale越大训练效果和检测效果越好，训练时img_scale设定过大会导致显存溢出，请视情况而定。

   ```
   ./configs/_base_/datasets/voc0712.py
   ```

<img src=".\pic\图片31.png" alt="图片31" style="zoom:61%;" />

8. 运行训练命令后

   `python ./tools/train.py configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py` 

   自动生产工作目录work_dirs保存：

   检查点文件；配置文件；Log日志文件

<img src=".\pic\图片32.png" alt="图片32" style="zoom:61%;" />

### 以Swin-Transformer+CoCo为例讲解目标识别

预训练网络结构： cascade_mask_rcnn_swin_base

下载连接：

https://github.com/SwinTransformer/storage/releases/download/v1.0.2/cascade_mask_rcnn_swin_base_patch4_window7.pth

1. 更改为自己数据集里的类别名称 `./mmdet/datasets/coco.py`

   <img src=".\pic\图片33.png" alt="图片33" style="zoom:67%;" />

2. 更改为自己的类别名称`./mmdet/core/evaluation/class_names.py`

   <img src=".\pic\图片34.png" alt="图片34" style="zoom:67%;" />

3. 将其中所有的num_classes更改为自制数据集的类别数目

   将所有的SyncBN用BN代替（不然会报错AssertionError: Default process group is not initialized）

   `./configs/swin/cascade_mask_rcnn_swin_base_patch4_window7_mstrain_480-800_giou_4conv1f_adamw_3x_coco.py`

   ![图片35](.\pic\图片35.png)

4. 同样更改num_classes为自己的类别数目`./configs/_base_/models/cascade_mask_rcnn_swin_fpn.py`

   ![图片36](.\pic\图片36.png)

5. 训练计划配置 `./configs/_base_/schedules/schedule_1x.py`

6. 训练时各项配置`./configs/_base_/default_runtime.py`

7. 运行以下脚本开始训练

   ```
   python ./tools/train.py   configs/swin/cascade_mask_rcnn_swin_base_patch4_window7_mstrain_480-800_giou_4conv1f_adamw_3x_coco.py
   ```
   
   出现如图界面即为开始训练

<img src=".\pic\图片37.png" alt="图片37" style="zoom:67%;" />

### 自训练网络进行检测

使用自训练网络进行检测，与之前使用预训练网络检测类似，修改`config_file`与`checkpoint_file`即可。

注意：

```
./mmdet/datasets/coco.py
./mmdet/core/evaluation/class_names.py
./mmdet/core/evaluation/class_names.py
```

用自训练网络进检测时，上述三个文件中的相应数据集的类别名称要与配置文件对应

例如:

配置文件为`faster_rcnn_r50_fpn_1x_coco.py`

自训练网络为`faster_rcnn_r50_fpn_1x_selfdataset.pth`

`coco.py`与`class_names.py`中的coco类别名称请改成与自制数据集相对应的。

## 更改可视化输出结果

1. imshow_det_bboxes（）为绘制目标框的函数

   `./mmdet/core/visualization/image.py`

<img src=".\pic\图片38.png" alt="图片38" style="zoom:67%;" />

2. imshow_det_bboxes()函数在此show_result()函数中调用

   `./mmdet/models/detectors/base.py`

   如果想改变输出图片可视化样式，请按注释更改。

<img src=".\pic\图片39.png" alt="图片39" style="zoom:67%;" />

如果不想将目标物体涂色，请将segms设为None。

<img src=".\pic\图片40.png" alt="图片40" style="zoom:67%;" />

3. 如何显示识别物体标号

   改动image.py内imshow_det_bboxes（）函数，如图将代码改动

   `label_text = class_names[label]+'_'+str(i) if class_names is not None else f'class {label}'`

<img src=".\pic\图片41.png" alt="图片41" style="zoom:61%;" />

4. 如何显示识别物体的数量

   在image.py内imshow_det_bboxes（）函数加入下面的代码，如图所示

   `cv2.putText(img,'number:'+str(len(labels)), (100,200), cv2.FONT_HERSHEY_SIMPLEX, 4,(72, 101, 241), 4, cv2.LINE_AA)`

   <img src=".\pic\图片42.png" alt="图片42" style="zoom:67%;" />

可视化更改结果:

![图片43](.\pic\图片43.png)
